{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecoFamr(레코팜) 농작물 수익예측 앱\n",
    "- Description \n",
    "    1. \n",
    "    2. \n",
    "- Git Repository : [https://github.com/Third3team/RecoFarm_app]\n",
    "- Date : 2024.04.13 ~\n",
    "- Author : Forrest DongGeun Park (pdg)\n",
    "- Update :\n",
    "    1. 2024.04.27 Sun by pdg\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'ko_KR.UTF-8/ko_KR.UTF-8/ko_KR.UTF-8/C/ko_KR.UTF-8/C'"
      ],
      "text/latex": [
       "'ko\\_KR.UTF-8/ko\\_KR.UTF-8/ko\\_KR.UTF-8/C/ko\\_KR.UTF-8/C'"
      ],
      "text/markdown": [
       "'ko_KR.UTF-8/ko_KR.UTF-8/ko_KR.UTF-8/C/ko_KR.UTF-8/C'"
      ],
      "text/plain": [
       "[1] \"ko_KR.UTF-8/ko_KR.UTF-8/ko_KR.UTF-8/C/ko_KR.UTF-8/C\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "필요한 패키지를 로딩중입니다: sysfonts\n",
      "\n",
      "필요한 패키지를 로딩중입니다: showtextdb\n",
      "\n",
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.0     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mbetween()\u001b[39m     masks \u001b[34mdata.table\u001b[39m::between()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m      masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfirst()\u001b[39m       masks \u001b[34mdata.table\u001b[39m::first()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mflatten()\u001b[39m     masks \u001b[34mjsonlite\u001b[39m::flatten()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32mhour()\u001b[39m    masks \u001b[34mdata.table\u001b[39m::hour()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32misoweek()\u001b[39m masks \u001b[34mdata.table\u001b[39m::isoweek()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m         masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlast()\u001b[39m        masks \u001b[34mdata.table\u001b[39m::last()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32mmday()\u001b[39m    masks \u001b[34mdata.table\u001b[39m::mday()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32mminute()\u001b[39m  masks \u001b[34mdata.table\u001b[39m::minute()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32mmonth()\u001b[39m   masks \u001b[34mdata.table\u001b[39m::month()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32mquarter()\u001b[39m masks \u001b[34mdata.table\u001b[39m::quarter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32msecond()\u001b[39m  masks \u001b[34mdata.table\u001b[39m::second()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mtranspose()\u001b[39m   masks \u001b[34mdata.table\u001b[39m::transpose()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32mwday()\u001b[39m    masks \u001b[34mdata.table\u001b[39m::wday()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32mweek()\u001b[39m    masks \u001b[34mdata.table\u001b[39m::week()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32myday()\u001b[39m    masks \u001b[34mdata.table\u001b[39m::yday()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mlubridate\u001b[39m::\u001b[32myear()\u001b[39m    masks \u001b[34mdata.table\u001b[39m::year()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "\n",
      "다음의 패키지를 부착합니다: ‘psych’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:ggplot2’:\n",
      "\n",
      "    %+%, alpha\n",
      "\n",
      "\n",
      "\n",
      "다음의 패키지를 부착합니다: ‘reshape2’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    smiths\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:data.table’:\n",
      "\n",
      "    dcast, melt\n",
      "\n",
      "\n",
      "\n",
      "다음의 패키지를 부착합니다: ‘plotrix’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:psych’:\n",
      "\n",
      "    rescale\n",
      "\n",
      "\n",
      "\n",
      "다음의 패키지를 부착합니다: ‘kableExtra’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    group_rows\n",
      "\n",
      "\n",
      "필요한 패키지를 로딩중입니다: lattice\n",
      "\n",
      "\n",
      "다음의 패키지를 부착합니다: ‘caret’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "\n",
      "randomForest 4.7-1.1\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n",
      "다음의 패키지를 부착합니다: ‘randomForest’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:psych’:\n",
      "\n",
      "    outlier\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------- # nolint\n",
    "## Descrition : Library 설치및 기본 세팅 세팅\n",
    "## Auhtor : Forrest DongGeun Park (PDG)\n",
    "## Update :\n",
    "    #2024.04.12 Sat\n",
    "        # 1. RandomForrest model 함수 추가\n",
    "    #2024.04.13 Sun\n",
    "        # 1. data Fetch 함수화\n",
    "    # 2024.04.26 Fri\n",
    "\t\t    # 1. 주석 업데이트 \n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "## Basic Settings\n",
    "    \n",
    "   \n",
    "    options(warn = -1) ## 경고 지우기\n",
    "    options(repr.plot.width=8, repr.plot.height=6) # 플랏 크기 조절\n",
    "    Sys.setlocale(category = \"LC_ALL\", locale = \"ko_KR.UTF-8\") # 한글 설정\n",
    "\n",
    "# Basic Graph Google Font Setting\n",
    "    library(showtext) ## plot : 구글 폰트 사용 \n",
    "    font_add_google(name = \"Noto Serif KR\",family = \"noto-serif\")\n",
    "    showtext_auto(TRUE)\n",
    "# Libraries for data fetching\n",
    "    library(jsonlite) # JSON file fetch\n",
    "    # fromJSON(\"\") #: json file fetch\n",
    "    library(XML) # XML file fetch\n",
    "    # xmlToDataFrame(\"\")\n",
    "    library(readxl) # excel file fetch\n",
    "    # read_excel(\"\", sheet =2)\n",
    "    library(data.table)\n",
    "    # tidyverse \n",
    "    library(tidyverse)\n",
    "\n",
    "## Data Fetch (csv)\n",
    "    dataFetch_csv <- function(csvfile_address){\n",
    "        ## Descrition : Data fetch function for csv file \n",
    "        ## Auhtor : Forrest Park\n",
    "        ## Update :\n",
    "        #2024.04.13 Sun\n",
    "            # 1. \n",
    "        ## CSV filez\n",
    "        return(read.csv(csvfile_address,na.strings=NA, header = T, sep=\",\",encoding = \"UTF-8\",fileEncoding=\"EUC-KR\")) \n",
    "    }\n",
    "\n",
    "## Data Fetch (txt)\n",
    "    dataFetch_txt <- function(txtfile_address){\n",
    "        ## Descrition : Data fetch function for txt file \n",
    "        ## Auhtor : Forrest Park\n",
    "        ## Update :\n",
    "        #2024.04.13 Sun\n",
    "            # 1. \n",
    "        return(readtable(txtfile_address, \n",
    "                encoding =\"EUC-KR\", fileEncoding =\"UTF-8\", \n",
    "                colnames =varnames,\n",
    "                hearder =F, skip =0, nrows =-1, sep=\"\"))\n",
    "    }\n",
    "\n",
    "## DataFetch ( xlsx)\n",
    "    dataFetch_xlsx <-function(xlsxfile_address){\n",
    "        ## Descrition : xlsx 파일에서 데이터 읽기\n",
    "        ## Auhtor : Forrest Park\n",
    "        ## Update :\n",
    "            #2024.04.13 Sun\n",
    "                # 1. \n",
    "        return(read_excel(xlsxfile_address))\n",
    "    } \n",
    "## 함수 정리 \n",
    "\n",
    "## 기본함수 : data, str, length, ncol, nrow, dim, ls, head, tail, library, \n",
    "    # data<- c(1,2,3)\n",
    "    # label = c('a','b','c')\n",
    "    # names(data)<-label\n",
    "    \n",
    "    # matrix( data, nrow= 2, ncol=3 , byrow=T)\n",
    "    # array(data, dim = c(2,3))\n",
    "    # list(data, \"hello\")\n",
    "    # factor(data, labels= label)\n",
    "\n",
    "## 기본 통계량 mean, median, min, max, range, sd, hist, barplot, stem, var\n",
    "    # range(data) #: data 의 최대 최소 출력\n",
    "    # var(data)  #: data 의 분산값 출력\n",
    "    # quantile(data, probs = 0.25) # :  사분위 수 출력 함수 \n",
    "\n",
    "## 데이터 처리 : apply, sapply, lapply \n",
    "\n",
    "## 데이터 시각화\n",
    "    # stem(col, scale =1)\n",
    "    # hist(data) # : data 의 histogram(연속 분포함수 ) \n",
    "    # barplot(data, ylim =c(0:10), main= \"title\", xlab=\"x label\", ylab=\"y label\", names =colnames(data)), \n",
    "\n",
    "\n",
    "## Libraries for DATA\n",
    "    library(stringr) # stringr 불러오기\n",
    "    library(dplyr) # dplyr : 데이터 가공 함수 -> \n",
    "    # filter(data,  a>1) : 특정 row 추출\n",
    "    # select(data, a, b) : 특정 column 추출\n",
    "    # arrange(data, desc(a))\n",
    "    # mutate(data, a_rank =rank(a)) # a칼럼 값을 기준으로 rank 를 매겨 새로운 랭크 칼럼을 생성\n",
    "    # distinct(data, a,b) # data 의 a, b 칼럼을 기준으로 중복된 행을 제거 (a와 b 가 동시에 중복)\n",
    "    # summarise(data, a_mean = mean(a), a_min= min(a), a_sd = sd(a) .. func(a)) # a 칼럼의 평균, 등등의 함수 값 요약. \n",
    "\n",
    "    library(descr) # descr : 데이터 설명 함수 \n",
    "    # freq(data, plot =F, main =\"title\") # : data row 별 빈도수 \n",
    "    library(psych) # psych : 데이터 시각화 함수 pairs.panel(iris)\n",
    "    # kurtosi(data) #: data 의 첨도값 출력 / psych \n",
    "    # skew(data) #: data 의 왜도값 출력 /psysy\n",
    "\n",
    "\n",
    "    library(reshape2) # data layout 변환 \n",
    "    library(ggplot2) # 그래프 \n",
    "    library(plotrix) # 3D pie\n",
    "    library(RColorBrewer) # color package\n",
    "    library(tidyverse)\n",
    "    library(hrbrthemes)\n",
    "    library(kableExtra)\n",
    "\n",
    "    library(caret) # data sampling \n",
    "    library(randomForest) # prediction model \n",
    "    library(nnet)\n",
    "\n",
    "\n",
    "#library(extrafont)\n",
    "# Functions \n",
    "dataDescription <- function(data){\n",
    "    columns <-c()\n",
    "    cat(\"\\n\\n *** 칼럼 별 데이터 빈도 조사 ***\\n\\nData Columns :  \",ncol(data),\"개\",\"\\n\\n\\n\")\n",
    "    for( i in 1:ncol(data)){\n",
    "        cat(\" \",i ,\". \", colnames(data)[i],\"\\n\", sep = \"\")\n",
    "        columnDesc(data[colnames(data)[i]])\n",
    "        columns<- append(columns,colnames(data)[i])\n",
    "    }\n",
    "    return(columns)\n",
    "}\n",
    "\n",
    "columnDesc<- function(column){\n",
    "\n",
    "    ## Descrition : 칼럼 데이터 설명 \n",
    "    ## Auhtor : Forrest Park\n",
    "    ## Update :\n",
    "        #2024.04.13 Sun\n",
    "            # 1. \n",
    "    par(bg = \"white\")\n",
    "    # 시장이름의 개수\n",
    "    cat( \"\\n ***[\",names(column), \"]칼럼의 데이터 종류 개수:\",nrow(unique(column)), sep = \"\")\n",
    "    # 가장 빈도가 많은 데이터와 적은 데이터 각각 5개 \n",
    "    dataFreq_top5<- head(arrange(as.data.frame(freq(as.matrix(column), plot =F)), desc(Frequency))[2:6,],5)\n",
    "    dataFreq_bot5<-tail(arrange(as.data.frame(freq(as.matrix(column), plot =F)), desc(Frequency)),5)\n",
    "    cat(\"\\n\\n-----[\",names(column),\"] 에서 가장 빈도가 많은 데이터 top 5 \\n\")\n",
    "    print(dataFreq_top5)\n",
    "    cat(\"\\n\\n-----[\",names(column),\"] 에서 가장 빈도가 적은 데이터 5 개 \\n\")\n",
    "    print(dataFreq_bot5)\n",
    "\n",
    "    cat(\"\\n\\n\\n\")\n",
    "\n",
    "}\n",
    "\n",
    "## 특정칼럼의 데이터를 모두 보고싶을 때 csv 로 변환하는 함수 \n",
    "\n",
    "column_csvSaving <- function(column_vector,title){\n",
    "    ##library(data.table)\n",
    "    ##library(tidyverse)\n",
    "    a_data<-as.data.frame(data.table(distinct(column_vector)))\n",
    "    write_csv(a_data,paste(title,\".csv\",sep =\"\"))\n",
    "}\n",
    "\n",
    "#  Error code -> 수정 피요\n",
    "# findWord_in_specific_colum <- function(data,찾을칼럼이름, 찾아야하는단어){\n",
    "#     ## Descrition : 특정칼럼에서 어떤단어를 포함하는 row 만 골라내기\n",
    "#     ## Auhtor : Forrest Park\n",
    "#     ## Update :\n",
    "#         #2024.04.27 Sun\n",
    "#             # 1. code 에서 에러남. 일단 주석 처리함. \n",
    "#     col_num <- which(colnames(data) == 찾을칼럼이름)\n",
    "#     selectedCol <- data[[찾을칼럼이름]] \n",
    "#     data %>% filter(str_detect(selectedCol,'배추'))\n",
    "# }\n",
    "#findWord_in_specific_colum(data,찾을칼럼이름, 찾아야하는단어)\n",
    "\n",
    "\n",
    "row_kind_show<-function(data){\n",
    "    ## Descrition : 각 칼럼에서의 값들이 어떤 것들이있는지 개수를 알려줌. \n",
    "    ## Auhtor : Forrest Park\n",
    "    ## Update :\n",
    "        #2024.04.13 Sun\n",
    "            # 1. \n",
    "    cols <- colnames(data)\n",
    "    for ( i in 1:length(cols)){\n",
    "        cat(paste(cols[i],'의 중복되지않은 개수 : ',length(unique(data[[cols[i]]])) ,sep=\"\"  ), \"\\n\")\n",
    "    }\n",
    "}\n",
    "#row_kind_show(data)\n",
    "\n",
    "## 특정 칼럼에서 중복되지 않은 값들을 백터로 반환하기\n",
    "\n",
    "unique_row_extract <- function(data,col_name) {\n",
    "    ## Descrition : 특정칼럼에서 중복되지 않은 값 추출\n",
    "    ## Auhtor : Forrest Park\n",
    "    ## Update :\n",
    "        #2024.04.13 Sun\n",
    "            # 1. \n",
    "    col_num <- which(colnames(data) == col_name)\n",
    "\n",
    "    result <-unique(data[[colnames(data)[col_num]]])\n",
    "    options(repr.plot.width=18, repr.plot.height=6) # 플랏 크기 조절\n",
    "\n",
    "    par(bg='white')\n",
    "    #freq(data[[colnames(data)[col_num]]],ylab= paste(col_name,'개수'))\n",
    "    freq_data<-as.data.frame(freq(data[[colnames(data)[col_num]]],plot = F))\n",
    "    a<-(freq(data[[colnames(data)[col_num]]],plot = F))\n",
    "  \n",
    "\n",
    "    colnames(freq_data)<- c(\"freq\",\"percent\")\n",
    "    cat( \"<<<\", col_name, \"에 있는 항목의 종류 와 빈도 >>>\\n\")\n",
    "    result<-(arrange(freq_data,desc(freq)))\n",
    "    print(result)\n",
    "    # for ( i in 1:nrow(result)){\n",
    "    #     cat(paste(\"  \",i, \". \",result[i,1],sep=\"\"),\"\\n\")\n",
    "    # }\n",
    "}\n",
    "#unique_row_extract(a,'품목')\n",
    "\n",
    "split_space_add_newcol <- function(data,target_colname,delimeter,splited_order,newcolname) {\n",
    "    ## Descrition : 특정칼럼에 있는 string 을 구분자로 split 하여 x 번째 를 새로운 칼럼에 넣어주는 함수\n",
    "    ## Auhtor : Forrest Park\n",
    "    ## Update :\n",
    "        #2024.04.13 Sun\n",
    "            # 1. \n",
    "    \n",
    "    col_num <- which(colnames(data) == target_colname)\n",
    "    selectedCol <- data[[target_colname]]\n",
    "\n",
    "\n",
    "    first_splited_word <- c()\n",
    "    for (i in 1:nrow(data)) {\n",
    "        first_splited_word <- c(first_splited_word, unlist(as.matrix((str_split(selectedCol, delimeter)))[i])[splited_order])\n",
    "    }\n",
    "   \n",
    "    data<- data%>% mutate(data,newcol= first_splited_word)\n",
    "    newcol_num <- which(colnames(data) == \"newcol\")\n",
    "\n",
    "    colnames(data)[newcol_num]<-newcolname\n",
    "    ## new coloum 을 맨 앞으로 \n",
    "    cols <-c(1:ncol(data))[-newcol_num]\n",
    "    newcolfirstcol<-c(newcol_num,cols)\n",
    "    #print(newcolfirstcol)\n",
    "    return(data[newcolfirstcol])\n",
    "}\n",
    "#split_delimeter_add_newcol(배추,'소재지',\" \",1,'시도')\n",
    "\n",
    "\n",
    "#a %>% filter(VGETBL_CL=='수박')\n",
    "# a_data<-as.data.frame(data.table(distinct(채소생산['VGETBL_CL'])))\n",
    "# write_csv(a_data,\"a_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
